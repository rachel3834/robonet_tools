{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0984ee27",
   "metadata": {},
   "source": [
    "# Procedure for Modeling a Microlensing Event\n",
    "\n",
    "In principle microlensing events are very simple - in Point Source, Point Lens (PSPL) events, there are just three essential parameters: \n",
    "t_0: Time of closest angular separation of the lens and source\n",
    "t_E: Einstein crossing time\n",
    "u_0: Impact parameter, or the closest angular separation\n",
    "\n",
    "The lightcurves of such events are perfectly smooth and symmetrical around the peak at t_0, since the magnification is purely a function of the angular separation.  \n",
    "\n",
    "But lensing is such an exquistely sensitive technique that a number of other factors can have a measureable influence on the morphology of the lightcurve.  Some of them can have very dramatic effects, such as for a binary event where the source trajectory passes across a caustic.  But some of them can be very subtle, such as parallax, which typically causes a skew in the lightcurve for stellar events.  \n",
    "\n",
    "Although these so-called \"second order effects\" add more parameters and complexity to the modeling procedure, they are very valuable, because a PSPL model tells us almost nothing about the phyiscal nature of the lensing object.  The finite extent of the source star's disk, represented by the rho parameter, and the parallax parameters pi_EN, pi_EE, for example need to be measured for us to determine the mass of the lensing object.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa18b2",
   "metadata": {},
   "source": [
    "In keeping with Occam's Raser though, we have to justify including additional parameters.  So the modeling procedure for an event is to start with the simplest possible model and include second order effects only when it is shown that to do so results in a measurably better fit.  This is usually evaluated by comparing the chisq of each fit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36317459",
   "metadata": {},
   "source": [
    "The usual sequence of models to fit is as follows.  Note that models that do not include parallax parameters are often referred to as 'static' models, since they neglect the movement of the Earth.  Also bear in mind that pyLIMA often uses the log10 of some parameters for computational reasons, although the parameters are presented here in their physical units. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2573f8c2",
   "metadata": {},
   "source": [
    "## Stage 1: Single lens models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afe4cb",
   "metadata": {},
   "source": [
    "We start by considering an isolated, single object as the lens, and a single source star. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b5ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Point Source, Point Lens\n",
    "PSPL_parameters = ['t0', 'u0', 'tE']\n",
    "\n",
    "# Static Finite Source, Point Lens:\n",
    "FSPL_parameters = ['t0', 'u0', 'tE', 'rho']\n",
    "\n",
    "# Finite Source, Point Lens with parallax:\n",
    "FSPLpi_parameters = ['t0', 'u0', 'tE', 'rho', 'piEN', 'piEE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd1c6f",
   "metadata": {},
   "source": [
    "Reasonable initial values for t_0, u_0 and t_E can be made from visual inspection of the lightcurve for the first PSPL model.  After that, the parameters of the best-fitting model in each case can be taken as the initial-guess parameters for the next, more complicated model.\n",
    "\n",
    "For those models where the finite size of the source star is important and the rho parameter must be calculated, then limb darkening of the source star becomes a key parameter.  All stars show some degree of limb-darkening depending on their surface temperature, and the linear coefficient used to describe the change in flux that this causes depends on wavelength.  For this reason, the coefficient used to model each lightcurve depends on the filter bandpass used to gather those data.  \n",
    "\n",
    "The coefficients are available from a paper by (Claret and Bloemen, 2011)[https://www.aanda.org/articles/aa/abs/2011/05/aa16451-11/aa16451-11.html], and should be assigned as attributes to each telescope as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_event.telescopes[0].ld_gamma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "522a61c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FSPL_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Code segment:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#...\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Fitting a static FSPL model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fspl \u001b[38;5;241m=\u001b[39m \u001b[43mFSPL_model\u001b[49m\u001b[38;5;241m.\u001b[39mFSPLmodel(event)\n\u001b[1;32m      6\u001b[0m fit1 \u001b[38;5;241m=\u001b[39m DE_fit\u001b[38;5;241m.\u001b[39mDEfit(fspl, display_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest1bin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m fit1\u001b[38;5;241m.\u001b[39mfit()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FSPL_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Code segment [incomplete won't run - see PyLIMA examples for full function]:\n",
    "#...\n",
    "\n",
    "# Fitting a static FSPL model\n",
    "fspl = FSPL_model.FSPLmodel(event)\n",
    "fit1 = DE_fit.DEfit(fspl, display_progress=False, strategy='best1bin')\n",
    "fit1.fit()\n",
    "\n",
    "# Store the best-fit static FSPL model parameters\n",
    "static_fspl_params = fit1.fit_results['best_model']\n",
    "\n",
    "# Configure a dynamic FSPL model\n",
    "fspl2 = FSPL_model.FSPLmodel(event, parallax=['Full',2.45935387e+06])\n",
    "fit2 = DE_fit.DEfit(fspl2, display_progress=False, strategy='best1bin')\n",
    "\n",
    "# ...give the previous best-fit parameter values as the starting guess:\n",
    "fit2.model_parameters_guess = static_fspl_params\n",
    "fit2.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632a0655",
   "metadata": {},
   "source": [
    "After each fit, its informative to examine the residuals lightcurves - i.e. the data - the model as a function of time.  If the model fully explains the photometric signature, then the residuals will be consistent with a straight line, and the data do not justify including further parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b2152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff6055c1",
   "metadata": {},
   "source": [
    "## Binary lens models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0198e3e",
   "metadata": {},
   "source": [
    "If at this point the residuals clearly indicate signal remaining in the data that is not explained by the model so far, we should start to consider binary lens models, by including the additional parameters:\n",
    "\n",
    "s: the projected separation of the binary lens components\n",
    "q: the ratio of the masses of the binary lens components\n",
    "alpha: the angle of the source's relative trajectory across the lens plane, relative to the axis of the binary.  \n",
    "\n",
    "However, in many cases the lightcurve shows very obvious signs that it is caused by a binary lens, such as sharp discontinuities that indicate caustic crossing events.  \n",
    "\n",
    "Either way, it's good practise to start by considering static models first (since they have the fewest parameters), then increase complexity if justified by the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you can always check the order of the parameters as used by PyLIMA using the following:\n",
    "fit.fit_parameters.keys()\n",
    "\n",
    "# Static Uniform Source, Binary Lens\n",
    "USBL_parameters = ['t0', 'u0', 'tE', 's', 'q', 'alpha']\n",
    "\n",
    "# Dynamic Uniform Source, Binary Lens\n",
    "USBL_parameters = ['t0', 'u0', 'tE', 'piEN', 'piEE', 's', 'q', 'alpha']\n",
    "\n",
    "# Static Finite Source, Point Lens:\n",
    "FSBL_parameters = ['t0', 'u0', 'tE', 'rho', 's', 'q', 'alpha']\n",
    "\n",
    "# Finite Source, Point Lens with parallax:\n",
    "FSBLpi_parameters = ['t0', 'u0', 'tE', 'rho', 'piEN', 'piEE', 's', 'q', 'alpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba43e43",
   "metadata": {},
   "source": [
    "It is also informative to plot the DE_population data as a function of parameters and chisq, as this often reveals the locations of one or more minima in parameter space.  \n",
    "\n",
    "The DE algorithm is very good at exploring parameter space but less good at quantifying the full uncertainties on each model parameter.   So we use DEfit to find the rough values of the model parameters at minima, *then do an MCMCfit starting from those parameters with the same type of model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd4b98a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Code segment [incomplete won't run - see PyLIMA examples for full function]:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Following on from fit2 above...\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Store the DE population data to a file:\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mfit2\u001b[49m\u001b[38;5;241m.\u001b[39mfit(computational_pool\u001b[38;5;241m=\u001b[39mpool)\n\u001b[1;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit2_results.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, fit2\u001b[38;5;241m.\u001b[39mfit_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDE_population\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Plot the DE population results:\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fit2' is not defined"
     ]
    }
   ],
   "source": [
    "# Code segment [incomplete won't run - see PyLIMA examples for full function]:\n",
    "# Following on from fit2 above...\n",
    "\n",
    "# Store the DE population data to a file:\n",
    "fit.fit(computational_pool=pool)\n",
    "np.save('fit_results.npy', fit.fit_results['DE_population'])\n",
    "\n",
    "# Plot the DE population results:\n",
    "plot_map_DE_population.map_DE_population('fit_results.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf8e06e",
   "metadata": {},
   "source": [
    "Note that the original map_DE_population function was designed to explore how chisq varies as a function of binary separation s and mass ratio q, since these parameters make the most impact on the shape of the binary caustic and this is the most important plot to make.  However, the code can be adapted to plot chisq as a function of the other model parameters if you wish, just by changing the index of the data array that is used for the plots, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code, line 44 plots columns 4 and 5, which for a binary model corresponds to s, q values:\n",
    "plt.hist2d(map_data_sort[index,4],map_data_sort[index,5],\n",
    "               norm=LogNorm(),bins=(30,30))\n",
    "# and also line 54, where column=-1 corresponds to the chisq value.\n",
    "plt.scatter(map_data[index,4],map_data[index,5],\n",
    "                c=np.log10(map_data[index,-1]),alpha=0.25)\n",
    "\n",
    "# The first columns in this file correspond to the order of the parameters given in the model, \n",
    "# so for example in our fit2 static FSBL model, the columns [0:7] are \n",
    "# ['t0', 'u0', 'tE', 'rho', 's', 'q', 'alpha']. \n",
    "\n",
    "# By adjusting the column indices used (and the plot axis labels), you can explore how chisq\n",
    "# varies as a function of these parameters.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f541fb8",
   "metadata": {},
   "source": [
    "Visually inspecting the DE population plot is a great way to see if there is more than one minimum in chisq - if so, this indicates that two physically different models might explain the available data similarly well.  This is sometimes called model degeneracy, and it is quite common when modeling very complex systems like microlensing events with many inter-related parameters.  So it is important to make sure that we explore all possible minima. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf3f19",
   "metadata": {},
   "source": [
    "So we use the DE population plots to identify combinations of (s,q) where minima exist.  For each minima, we use MCMC to fully map the shape of each minimum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39873cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g. suppose we have performed a DEfit for a dynamic FSBL model and \n",
    "# found two minima at (s1,q1) and (s2,q2).  \n",
    "\n",
    "# We can get most of the initial-guess parameters for our MCMC runs from the fit_results \n",
    "# for the FSBL model:\n",
    "fsbl_params = fit1.fit_results['best_model']\n",
    "\n",
    "# We will now set up two arrays of initial-guess parameters for the MCMC runs for the two\n",
    "# different minima by substituting the values of (s,q) -> {(s1,q1), and (s2,q2)}:\n",
    "guess1 = copy.copy(fsbl_params)\n",
    "guess1[6] = s1\n",
    "guess1[7] = q1\n",
    "\n",
    "guess2 = copy.copy(fsbl_params)\n",
    "guess2[6] = s2\n",
    "guess2[7] = q2\n",
    "\n",
    "# Then we configure dynamic FSPL models for the MCMC fits for both minima.  Note that this \n",
    "# is the same type of model we used for the previous DEfit.  \n",
    "fsbl = FSPL_model.FSPLmodel(event, parallax=['Full',2.45935387e+06])\n",
    "fit2 = MCMC_fit.MCMCfit(fsbl)\n",
    "fit2.model_parameters_guess = guess1\n",
    "fit2.fit()\n",
    "\n",
    "fit3 = MCMC_fit.MCMCfit(fsbl)\n",
    "fit3.model_parameters_guess = guess2\n",
    "fit3.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046bb03",
   "metadata": {},
   "source": [
    "The results of the MCMC fits for all of the minima should be stored, and the best-fitting model parameters and chisq recorded in your paper draft for comparison, to see which best explains the lightcurve data.  Here again we inspect the lightcurve residuals. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a16c34",
   "metadata": {},
   "source": [
    "## Binary Source Models\n",
    "\n",
    "There is one more category of models that we should consider: binary source.  Binary stars are very common in the Galaxy, so it is not unexpected that we occasionally see the effects of the source star, rather than the lensing object, having a companion in the lightcurve of the event.  Sometimes binary source lightcurves can be very similar to binary lens lightcurves, so we need to check to see which possibility fits the data best.  \n",
    "\n",
    "PyLIMA's syntax for using a binary source model should be familiar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dspl_parameters = [to, uo, delta_to, delta_uo, tE, q_fluxr_1, q_fluxr2, ...] \n",
    "# where q_fluxr_* is the flux ratio in each observing band.\n",
    "dspl = DSPL_model.DSPLmodel(your_event)\n",
    "\n",
    "# And the same syntax for the fitting the model can be used with any of the usual fitting \n",
    "# routines:\n",
    "fit4 = MCMC_fit.MCMCfit(dspl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b69b06",
   "metadata": {},
   "source": [
    "## Reevaluating the photometric uncertainties\n",
    "\n",
    "Once we have a model that provides a good fit for the data, it is important to take a step back and examine the quality of our data.  Real-world photometry has many sources of noise, including systematic correlated (or \"red\") noise which is not well described by the quoted uncertainties on the flux measurements produced by most data pipelines.  \n",
    "\n",
    "Spuriously outlying datapoints with under-estimated uncertainties can cause problems when we compare models like this, because they have a disproportional impact on the resulting chisq, and sometimes cause the fitting process to erroneously fit poor data instead of higher quality points.  Sometimes we avoid this by removing obviously-poor quality points at the data reduction stage, but despite this, outlyers are not always obvious and the uncertainties are still likely to be under-estimated.  \n",
    "\n",
    "Therefore it is common practise to re-evaluate all datapoints in the event lightcurve by comparing it to the model, *but only after a well-fitting model has been identified!*\n",
    "\n",
    "PyLIMA provides options to include the error rescaling during the fitting process, once a good-fit model has been found.  The procedure is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This option will compute a log_10(k) for each telescopes in the chain, where\n",
    "# sig_' = 10^(log_10(k)) x sig  and sig represents the flux error for each telescope.\n",
    "refined_fit = MCMC_fit.MCMCfit(mymodel, rescale_photometry=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
